# Diagn√≥stico: Configura√ß√µes de IA n√£o refletidas nos prompts/LLM

**Data:** 2025-12-07
**Status:** üî¥ Confirmado - Root cause identificado
**Prioridade:** Alta

---

## üìã Sum√°rio Executivo

**Problema:** A tela de Configura√ß√µes > Prompts de IA permite editar modelo, temperatura, dossi√™ e prompts customizados, mas as rotas de IA (`/api/ai/parse-job`, `/api/ai/generate-resume`) **ignoram completamente** essas configura√ß√µes e continuam usando valores hardcoded.

**Impacto:**

- Dossi√™ customizado (Engenharia Qu√≠mica, Bertioga/SP) n√£o √© usado
- An√°lises de vaga assumem perfil errado (Engenharia de Software / Computa√ß√£o)
- Modelo exibido na UI (Gemini) n√£o corresponde ao usado (Grok)
- Par√¢metros de temperatura/tokens n√£o s√£o aplicados

**Root Cause:** Rotas de IA n√£o chamam `loadUserAIConfig()` nem usam `PromptsConfig`. Usam prompts/perfil hardcoded.

---

## üîç Phase 1: Root Cause Investigation

### 1. Onde as configs s√£o salvas

**Fonte de verdade:**

- **Tabela Supabase:** `prompts_config`
- **Servi√ßo:** `lib/supabase/prompts.ts`
  - `getPromptsConfig(userId)` - L√™ configs (user-specific ou global default)
  - `savePromptsConfig(config, userId)` - Salva/atualiza configs
- **Tipo:** `PromptsConfig` em `lib/types.ts`

**UI:**

- **Componente:** `components/configuracoes-prompts.tsx`
- **API Route:** `app/api/prompts/route.ts`
  - GET: retorna configs via `getPromptsConfig()`
  - POST: salva via `savePromptsConfig()`

**Campos persistidos:**

```typescript
{
  modelo_gemini: string       // Ex: "x-ai/grok-4.1-fast"
  temperatura: number         // 0.0 - 1.0
  max_tokens: number          // 512 - 32768
  top_p?: number
  top_k?: number
  dossie_prompt: string       // Perfil do candidato
  analise_prompt: string      // Regras de an√°lise
  curriculo_prompt: string    // Regras de curr√≠culo
}
```

**‚úÖ Conclus√£o:** Sistema de persist√™ncia **funciona perfeitamente**. Configs salvam e leem corretamente.

---

### 2. Onde os prompts/modelo s√£o montados hoje (rotas de IA)

#### Rota: `/api/ai/parse-job`

**Arquivo:** `app/api/ai/parse-job/route.ts`
**Fun√ß√£o:** `parseJobWithAnalysis()` em `lib/ai/job-parser.ts`

**Linha 437 (`job-parser.ts`):**

```typescript
const prompt = buildJobAnalysisPrompt(jobDescription, USER_PROFILE) // ‚ùå HARDCODED
```

**USER_PROFILE hardcoded (`lib/ai/user-profile.ts:17-26`):**

```typescript
export const USER_PROFILE: UserProfile = {
  skills: ["TypeScript", "React", "Next.js", "Node.js", ...],
  education: "Cursando Engenharia de Software / Ci√™ncia da Computa√ß√£o",  // ‚ùå ERRADO!
  goals: "Conseguir est√°gio em tech para ganhar experi√™ncia pr√°tica em desenvolvimento de software",
}
```

**buildJobAnalysisPrompt() (`lib/ai/analysis-prompts.ts:38-54`):**

```typescript
export function buildJobAnalysisPrompt(jobDescription: string, userProfile: UserProfile): string {
  return `
  2. Perfil do Candidato:
  - Habilidades: ${userProfile.skills.join(", ")}      // ‚ùå USA USER_PROFILE HARDCODED
  - Experi√™ncia: ${userProfile.experience.join("; ")}
  - Forma√ß√£o: ${userProfile.education}                  // ‚ùå "Eng. Software", n√£o "Eng. Qu√≠mica"
  - Objetivos: ${userProfile.goals}
  `
}
```

**Modelo usado (`lib/ai/config.ts:9-14`):**

```typescript
export const AI_MODEL_CONFIG = {
  model: "x-ai/grok-4.1-fast", // ‚úÖ Correto (Grok)
  temperature: 0.7, // ‚ùå Hardcoded, n√£o usa config.temperatura
  maxOutputTokens: 4096, // ‚ùå Hardcoded, n√£o usa config.max_tokens
  topP: 0.9, // ‚ùå Hardcoded, n√£o usa config.top_p
}
```

**‚ùå Problema:** `parseJobWithAnalysis()` **NUNCA** chama:

- `loadUserAIConfig(userId)` (existe mas n√£o √© usado)
- `config.dossie_prompt` (existe mas √© ignorado)
- `getGenerationConfig(config)` (existe mas n√£o √© usado)

#### Rota: `/api/ai/generate-resume`

**An√°lise pendente** - provavelmente mesmo padr√£o (prompts hardcoded).

---

### 3. Existe servi√ßo central de settings?

**‚úÖ SIM!** Infraestrutura completa j√° existe em `lib/ai/config.ts`:

**Fun√ß√µes prontas mas N√ÉO USADAS:**

```typescript
// lib/ai/config.ts:114-116
export async function loadUserAIConfig(userId?: string): Promise<PromptsConfig> {
  return await getPromptsConfig(userId)
}

// lib/ai/config.ts:125-131
export function getGenerationConfig(config: PromptsConfig) {
  return {
    temperature: config.temperatura,
    maxOutputTokens: config.max_tokens,
    topP: config.top_p,
  }
}
```

**‚úÖ Conclus√£o:** Fun√ß√µes j√° existem para integra√ß√£o, mas **rotas de IA n√£o as chamam**.

---

## üéØ Root Cause Summary

| Componente               | Status                    | Problema                                       |
| ------------------------ | ------------------------- | ---------------------------------------------- |
| UI de Configs            | ‚úÖ Funciona               | Salva/l√™ corretamente de Supabase              |
| API `/api/prompts`       | ‚úÖ Funciona               | GET/POST usando `getPromptsConfig()`           |
| Servi√ßo `prompts.ts`     | ‚úÖ Funciona               | Persist√™ncia funcional                         |
| Tipo `PromptsConfig`     | ‚úÖ Funciona               | Schema correto                                 |
| Fun√ß√µes de integra√ß√£o    | ‚ö†Ô∏è Existem mas n√£o usadas | `loadUserAIConfig()`, `getGenerationConfig()`  |
| **Rotas de IA**          | ‚ùå **IGNORAM CONFIGS**    | Usam `USER_PROFILE` hardcoded                  |
| **Prompts de an√°lise**   | ‚ùå **HARDCODED**          | `analysis-prompts.ts` n√£o usa `dossie_prompt`  |
| **Par√¢metros do modelo** | ‚ùå **HARDCODED**          | `AI_MODEL_CONFIG` n√£o usa `config.temperatura` |

**Root Cause:**
As rotas de IA (`parse-job`, `generate-resume`) usam:

- ‚ùå `USER_PROFILE` hardcoded em vez de `config.dossie_prompt`
- ‚ùå `AI_MODEL_CONFIG` hardcoded em vez de `getGenerationConfig(config)`
- ‚ùå Prompts hardcoded em `analysis-prompts.ts` em vez de `config.analise_prompt`

**Infraestrutura de integra√ß√£o existe, mas n√£o √© chamada pelas rotas.**

---

## üìù Phase 2: Plano de Corre√ß√£o

### Objetivo

Fazer com que as rotas de IA (`/api/ai/parse-job`, `/api/ai/generate-resume`) leiam e usem as configura√ß√µes salvas em `prompts_config` via `loadUserAIConfig()`.

### Fonte de Verdade √önica

**Tabela:** `prompts_config` (Supabase)
**Servi√ßo:** `lib/supabase/prompts.ts` (`getPromptsConfig`, `savePromptsConfig`)
**Tipo:** `PromptsConfig` (`lib/types.ts`)

**Campos:**

- `modelo_gemini`: Nome do modelo (Grok via OpenRouter)
- `temperatura`, `max_tokens`, `top_p`, `top_k`: Par√¢metros de gera√ß√£o
- `dossie_prompt`: Perfil completo do candidato (substitui `USER_PROFILE`)
- `analise_prompt`: Regras de an√°lise de vaga
- `curriculo_prompt`: Regras de personaliza√ß√£o de curr√≠culo

### Estrat√©gia de Implementa√ß√£o

**Princ√≠pio:** Usar fun√ß√µes existentes (`loadUserAIConfig`, `getGenerationConfig`) nas rotas de IA.

### Batches de Implementa√ß√£o

#### Batch A: Integra√ß√£o no Job Parser

**Arquivos afetados:**

- `lib/ai/job-parser.ts` (parseJobWithAnalysis)
- `lib/ai/analysis-prompts.ts` (buildJobAnalysisPrompt)

**Mudan√ßas:**

1. **`job-parser.ts:parseJobWithAnalysis()`**
   - Adicionar par√¢metro `userId?: string`
   - Chamar `loadUserAIConfig(userId)` no in√≠cio
   - Passar `config` para `buildJobAnalysisPrompt()`
   - Usar `config.dossie_prompt` em vez de `USER_PROFILE`
   - Usar `getGenerationConfig(config)` para par√¢metros do modelo

2. **`analysis-prompts.ts:buildJobAnalysisPrompt()`**
   - Remover par√¢metro `userProfile: UserProfile`
   - Adicionar par√¢metro `dossiePrompt: string`
   - Substituir interpola√ß√£o de `userProfile.*` por inclus√£o direta de `dossiePrompt`

3. **`app/api/ai/parse-job/route.ts`**
   - Obter `userId` da sess√£o (`supabase.auth.getUser()`)
   - Passar `userId` para `parseJobWithAnalysis(jobDescription, { userId })`

**Resultado esperado:**

- An√°lise de vaga usa dossi√™ salvo (Engenharia Qu√≠mica, Bertioga/SP)
- Par√¢metros do modelo (temperatura, tokens) v√™m de `prompts_config`

#### Batch B: Integra√ß√£o no Resume Generator

**Arquivos afetados:**

- `lib/ai/resume-generator.ts`
- `app/api/ai/generate-resume/route.ts`

**Mudan√ßas:**

1. **`resume-generator.ts`**
   - Adicionar par√¢metro `userId?: string`
   - Chamar `loadUserAIConfig(userId)`
   - Usar `config.curriculo_prompt` para system instruction
   - Usar `getGenerationConfig(config)` para par√¢metros

2. **`app/api/ai/generate-resume/route.ts`**
   - Obter `userId` da sess√£o
   - Passar para gerador de curr√≠culo

**Resultado esperado:**

- Curr√≠culo personalizado usa regras salvas em `config.curriculo_prompt`

#### Batch C: Atualiza√ß√£o da UI de Configura√ß√µes

**Arquivos afetados:**

- `components/configuracoes-prompts.tsx` (labels, help text)

**Mudan√ßas:**

1. Trocar label "Modelo Gemini" ‚Üí "Modelo LLM" (linha 207)
2. Atualizar placeholder: `"gemini-2.5-flash"` ‚Üí `"x-ai/grok-4.1-fast"` (linha 212)
3. Atualizar texto explicativo para mencionar Grok/OpenRouter (linha 215)
4. Atualizar descri√ß√£o do card (linha 160): remover men√ß√£o a "Gemini"

**Resultado esperado:**

- UI mostra modelo correto (Grok)
- Usu√°rio sabe que √© OpenRouter, n√£o Gemini

#### Batch D: Depreca√ß√£o de Arquivos Hardcoded

**Arquivos para remover (ap√≥s Batch A/B):**

- `lib/ai/user-profile.ts` - Substitu√≠do por `config.dossie_prompt`

**Arquivos para documentar como deprecated:**

- `lib/ai/prompts.ts` - Se contiver prompts n√£o usados
- Fun√ß√µes hardcoded em `analysis-prompts.ts` - Manter apenas wrappers para `config.*`

**Resultado esperado:**

- C√≥digo mais limpo, sem duplica√ß√£o de fonte de verdade

#### Batch E: Testes

**Testes a criar/atualizar:**

1. **Unit Test:** `lib/ai/config.test.ts`
   - Testar `loadUserAIConfig(userId)` retorna config correta
   - Testar `getGenerationConfig(config)` extrai campos certos

2. **Integration Test:** `__tests__/api/ai/parse-job.test.ts`
   - Criar config customizada via `savePromptsConfig()`
   - Chamar `/api/ai/parse-job`
   - Verificar que an√°lise menciona dados do dossi√™ customizado (n√£o hardcoded)

3. **E2E Test (Playwright):** `tests/e2e/ia-settings.spec.ts`
   - Acessar Configura√ß√µes > Prompts de IA
   - Atualizar dossi√™ (mudar forma√ß√£o, localiza√ß√£o)
   - Salvar
   - Ir para an√°lise de vaga
   - Verificar que texto da an√°lise reflete novo dossi√™

**Resultado esperado:**

- Cobertura de testes garante que configs s√£o aplicadas
- Regress√£o detect√°vel se rotas voltarem a usar hardcoded

---

## ‚úÖ Crit√©rios de Pronto

**Batch A (Job Parser):**

- [ ] `parseJobWithAnalysis()` chama `loadUserAIConfig(userId)`
- [ ] Dossi√™ usado vem de `config.dossie_prompt`, n√£o `USER_PROFILE`
- [ ] Par√¢metros do modelo v√™m de `getGenerationConfig(config)`
- [ ] An√°lise de vaga menciona "Engenharia Qu√≠mica" e "Bertioga/SP" (do dossi√™ salvo)

**Batch B (Resume Generator):**

- [ ] Gerador de curr√≠culo usa `config.curriculo_prompt`
- [ ] Par√¢metros do modelo v√™m de `getGenerationConfig(config)`

**Batch C (UI):**

- [ ] Label exibe "Modelo LLM" (n√£o "Modelo Gemini")
- [ ] Placeholder mostra `x-ai/grok-4.1-fast`
- [ ] Descri√ß√£o menciona OpenRouter/Grok

**Batch D (Cleanup):**

- [ ] `user-profile.ts` removido
- [ ] Imports de `USER_PROFILE` removidos
- [ ] Fun√ß√µes hardcoded documentadas como deprecated

**Batch E (Testes):**

- [ ] Teste unit√°rio para `loadUserAIConfig()` passa
- [ ] Teste de integra√ß√£o valida uso de config customizada
- [ ] Teste E2E confirma que dossi√™ atualizado reflete na an√°lise

**Bug Resolvido:**

- [ ] An√°lise de vaga **N√ÉO menciona mais** "engenheiro de computa√ß√£o"
- [ ] An√°lise de vaga **USA** perfil salvo (Engenharia Qu√≠mica, Bertioga/SP)
- [ ] UI mostra modelo correto (Grok)
- [ ] Par√¢metros salvos (temperatura, tokens) s√£o aplicados nas chamadas de IA

---

## üìä Evid√™ncias Coletadas (Phase 1)

### Arquivos Lidos

| Arquivo                                | Papel                  | Conclus√£o                             |
| -------------------------------------- | ---------------------- | ------------------------------------- |
| `components/configuracoes-prompts.tsx` | UI de configs          | ‚úÖ Funciona corretamente              |
| `app/api/prompts/route.ts`             | API de configs         | ‚úÖ GET/POST funcionais                |
| `lib/supabase/prompts.ts`              | Persist√™ncia           | ‚úÖ CRUD funcional                     |
| `lib/types.ts`                         | Schema `PromptsConfig` | ‚úÖ Tipo correto                       |
| `lib/ai/config.ts`                     | Fun√ß√µes de integra√ß√£o  | ‚ö†Ô∏è Existem mas n√£o usadas             |
| `lib/ai/job-parser.ts`                 | Parser de vaga         | ‚ùå Usa `USER_PROFILE` hardcoded       |
| `lib/ai/user-profile.ts`               | Perfil hardcoded       | ‚ùå "Eng. Software" (errado!)          |
| `lib/ai/analysis-prompts.ts`           | Prompts de an√°lise     | ‚ùå Interpola `USER_PROFILE` hardcoded |

### Linhas Cr√≠ticas

**`job-parser.ts:437`**

```typescript
const prompt = buildJobAnalysisPrompt(jobDescription, USER_PROFILE) // ‚ùå N√ÉO USA CONFIG
```

**`user-profile.ts:17-26`**

```typescript
export const USER_PROFILE: UserProfile = {
  education: "Cursando Engenharia de Software / Ci√™ncia da Computa√ß√£o", // ‚ùå ERRADO
  // Deveria ser: "Engenharia Qu√≠mica (UNESP)"
}
```

**`config.ts:114-116` (existe mas n√£o √© chamado)**

```typescript
export async function loadUserAIConfig(userId?: string): Promise<PromptsConfig> {
  return await getPromptsConfig(userId) // ‚úÖ Fun√ß√£o pronta, s√≥ falta usar!
}
```

---

## üîÑ Pr√≥ximos Passos

1. ‚úÖ **Phase 1 completa:** Diagn√≥stico documentado
2. ‚è≠Ô∏è **Aprova√ß√£o do plano:** Revisar este documento com usu√°rio
3. ‚è≠Ô∏è **Phase 3:** Implementar Batch A (Job Parser)
4. ‚è≠Ô∏è **Phase 3:** Implementar Batch B (Resume Generator)
5. ‚è≠Ô∏è **Phase 3:** Implementar Batch C (UI labels)
6. ‚è≠Ô∏è **Phase 3:** Implementar Batch D (Cleanup)
7. ‚è≠Ô∏è **Phase 3:** Implementar Batch E (Testes)
8. ‚è≠Ô∏è **Verifica√ß√£o final:** Confirmar que an√°lise usa dossi√™ correto

---

**Diagnostic completed:** 2025-12-07
**Agent:** Claude Sonnet 4.5 (systematic-debugging skill)
**Next:** Aguardando aprova√ß√£o para Phase 3 (implementa√ß√£o)
